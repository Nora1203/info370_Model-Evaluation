{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab27f102-3a0b-4f2f-a8ea-9770ac6d5dbe",
   "metadata": {},
   "source": [
    "## 1.1 Load and prepar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35e2a8da-bcea-42ad-9848-a0692262de55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>Other</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age c_charge_degree              race          age_cat   sex  priors_count  \\\n",
       "0   69               F             Other  Greater than 45  Male             0   \n",
       "1   34               F  African-American          25 - 45  Male             0   \n",
       "2   24               F  African-American     Less than 25  Male             4   \n",
       "3   44               M             Other          25 - 45  Male             0   \n",
       "4   41               F         Caucasian          25 - 45  Male            14   \n",
       "\n",
       "   decile_score  two_year_recid  \n",
       "0             1               0  \n",
       "1             3               1  \n",
       "2             4               1  \n",
       "3             1               0  \n",
       "4             6               1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"data/compas-score-data.csv.bz2\", sep = \"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f47e0c93-50c9-4302-8033-b45a2ab0f659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6172, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a467dad-a3f6-42df-bfd0-111e66ce99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "df = df[(df.race == \"Caucasian\") | (df.race == \"African-American\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e903a16-cb41-44f1-94e4-7b5a5431d93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>high_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>21</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>32</td>\n",
       "      <td>F</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age c_charge_degree              race       age_cat   sex  priors_count  \\\n",
       "2302   21               F  African-American  Less than 25  Male             1   \n",
       "721    26               M         Caucasian       25 - 45  Male             4   \n",
       "907    27               F  African-American       25 - 45  Male             2   \n",
       "4782   29               M  African-American       25 - 45  Male             0   \n",
       "4916   32               F         Caucasian       25 - 45  Male             3   \n",
       "\n",
       "      decile_score  two_year_recid  high_score  \n",
       "2302             3               0           0  \n",
       "721              7               1           1  \n",
       "907              5               0           1  \n",
       "4782             2               0           0  \n",
       "4916             5               0           1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "# Create a new column 'high_score' and initialize it with 0\n",
    "df['high_score'] = 0\n",
    "\n",
    "# Update 'high_score' to 1 for individuals with decile_score 5 and above\n",
    "df.loc[df['decile_score'] >= 5, 'high_score'] = 1\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0d4b8be-b074-4290-a554-449aca7e3446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high_score\n",
       "0    0.320015\n",
       "1    0.634455\n",
       "Name: two_year_recid, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "# a\n",
    "recid_risk = df.groupby(\"high_score\")[\"two_year_recid\"].mean()\n",
    "recid_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a8c185-f031-4a8e-a478-b3f4aee2e61b",
   "metadata": {},
   "source": [
    "The recidivism rate for low-risk individuals is 32%\n",
    "\n",
    "The recidivism rate for high-risk individuals is 63.45%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6025477c-d43c-4ab9-8066-21e33d24591a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "African-American    0.52315\n",
       "Caucasian           0.39087\n",
       "Name: two_year_recid, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b\n",
    "recid_race = df.groupby(\"race\")[\"two_year_recid\"].mean()\n",
    "recid_race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2769e5-67d7-4609-b05a-903bc0a5598f",
   "metadata": {},
   "source": [
    "The recidivism rate for African-Americans is 52.32%\n",
    "\n",
    "The recidivism rate for Caucasians is 39.09%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1e22bed-94c3-4268-9fd1-b3fb19871b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1872,  923],\n",
       "       [ 881, 1602]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# \"high_score\" is COMPAS prediction and \"two_year_recid\" variable is actual recidivism\n",
    "cm = confusion_matrix(df['two_year_recid'], df['high_score'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7143eec9-737f-4a0f-ba91-1b04b93cd5e2",
   "metadata": {},
   "source": [
    "Accuracy = (TP + TN) / T = (1602 + 1872) / (1872 + 923 + 881 + 1602) = 0.658\n",
    "\n",
    "Precision = TP / (TP + FP) = 1602 / (1602 + 923) = 0.634\n",
    "\n",
    "Recall = TP / (TP + FN) = 1602 / (1602 + 881) = 0.645\n",
    "\n",
    "True Negative (TN): Individuals correctly classified as low risk by COMPAS and did not recidivate.\\\n",
    "False Positive (FP): Individuals incorrectly classified as high risk by COMPAS but did not recidivate.\\\n",
    "False Negative (FN): Individuals incorrectly classified as low risk by COMPAS but recidivated.\\\n",
    "True Positive (TP): Individuals correctly classified as high risk by COMPAS and recidivated.\n",
    "\n",
    "Accuracy = 0.658 means that out of all the individuals in the dataset, about 65.8% were correctly classified by COMPAS as either low risk or high risk based on their decile scores.\\\n",
    "Precision = 0.634 means that out of all the individuals classified as high risk by COMPAS, around 63.4% of them actually recidivated within two years.\\\n",
    "Recall = 0.6452 means that out of all the individuals who actually recidivated within two years, around 64.5% of them were correctly identified as high risk by COMPAS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f730f89-6845-4387-abd3-b3992cae2c39",
   "metadata": {},
   "source": [
    "Q6\n",
    "\n",
    "Accuracy: the proportion of correct predictions (both true positives and true negatives) out of the total number of predictions. In this case, accuracy = 0.658 means that out of all the individuals in the dataset, about 65.8% were correctly classified by COMPAS as either low risk or high risk based on their decile scores.\n",
    "\n",
    "Percentage of low-risk individuals wrongly classified as high risk: This corresponds to the false positive rate (FPR), FPR = FP / (TN + FP) = 923 / (1872 + 923) = 0.33. This means that about 33% of individuals who were actually low risk according to COMPAS were wrongly classified as high risk.\n",
    "\n",
    "Percentage of high-risk individuals wrongly classified as low risk: This corresponds to the false negative rate (FNR), FNR = FN / (TP + FN) = 881 / (1602 + 881) = 0.3548. This means that approximately 35.48% of individuals who were actually high risk according to COMPAS were wrongly classified as low risk.\n",
    "\n",
    "I don't feel comfortable having a judge use COMPAS to inform sentencing guidelines since the FPR and FNR indicated that almost one-third of the individuals were classified in the wrong category. Using the COMPAS alone may lead individuals who are not potentially more dangerous to be more punished, as well as leading some vicious criminals to escape due punishment.\n",
    "\n",
    "I believe that judges who perform the same task without COMPAS's help have a better outcome. This is because judges at the court have many years of experience, training, and a profound understanding of the law. More importantly, compared to quantitative data, judges also need some qualitative data, such as the offender's attitudes, their criminal motives, the action of repentance, and other factors, to make informed decisions.\n",
    "\n",
    "I would say the law system need to aim for errors to be as low as possible, in terms of quantitative data, the ideal rate could be lower than 3% for me. Comparing the acceptable error rate for human judges and algorithms, if we assume that the judges of algorithms do not involve any human intervention, then I think the error rate of algorithms should be 0%. This is because in the role of human judges, suspects' sentence are often involved in a large number of legal workers to gather evidence, defending, and decide on sentences before they are convicted. This also means that there will be more people monitoring the correctness of the individual's conviction, and the suspect will be able to get more opportunities to defend themselves.\n",
    "\n",
    "It's hard to say judges can perform the same tasks better or worse. Both human judeges and algorithms have strengths and weaknesses. Algorithms like COMPAS can provide consistency and objectivity in their decision-making process, but they can also be influenced by biases present in the data used to train them. Human judges, on the other hand, may bring contextual understanding and subjective judgment to their decision-making, but they can be susceptible to individual biases and inconsistencies.\n",
    "\n",
    "The acceptable error rate may differ for human judges and algorithms. While fairness and accuracy should be sought in both cases, the mechanisms of bias and error can be different. In my point of view, a 5% misclassification risk is  acceptable for the human judeges, and a 10% misclassification risk is acceptable for the algorithms. This is because human judges possess the ability to consider the nuances and contextual factors of individual cases. They can take into account a wide range of information, including personal history, mitigating circumstances, and individual characteristics. This contextual understanding allows judges to make informed decisions that may deviate from strict algorithmic predictions. It is essential to strike a balance between human judgment and algorithmic assistance. The goal should be to continually improve the accuracy, fairness, and transparency of both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37cfdc1-754e-4cc0-ae3a-000ce314c9a2",
   "metadata": {},
   "source": [
    "## 1.2 Analysis by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "659f5e4b-f1e8-4ed9-abc0-16744b4bec8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6495352651722253,\n",
       " 0.3514115898959881,\n",
       " 0.5948275862068966,\n",
       " 0.2899786780383795)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "hAA = df[(df.race == \"African-American\") & (df.high_score == 1)]\n",
    "lAA = df[(df.race == \"African-American\") & (df.high_score == 0)]\n",
    "hCC = df[(df.race == \"Caucasian\") & (df.high_score == 1)]\n",
    "lCC = df[(df.race == \"Caucasian\") & (df.high_score == 0)]\n",
    "\n",
    "hAA_recid = np.mean(hAA.two_year_recid)\n",
    "lAA_recid = np.mean(lAA.two_year_recid)\n",
    "hCC_recid = np.mean(hCC.two_year_recid)\n",
    "lCC_recid = np.mean(lCC.two_year_recid)\n",
    "\n",
    "hAA_recid, lAA_recid, hCC_recid, lCC_recid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d262a52-d9fb-497a-9218-bd20117c54a5",
   "metadata": {},
   "source": [
    "The recidivism rate for high-risk African-Americans is 64.95%.\\\n",
    "The recidivism rate for low-risk African-Americans is 35.14%.\\\n",
    "The recidivism rate for high-risk Caucasians is 59.48%.\\\n",
    "The recidivism rate for low-risk Caucasians is 29.00%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9251812c-e640-4fb9-b6d5-c2a9bc289939",
   "metadata": {},
   "source": [
    "Q2\n",
    "\n",
    "Based on the analysis of the results, it can be observed that the recidivism rate for high-risk African-Americans (64.95%) is 5.47% higher than that of high-risk Caucasians (59.48%). Similarly, the recidivism rate for low-risk African-Americans (35.14%) is 6.14% higher than that of low-risk Caucasians (29%).\n",
    "\n",
    "These findings indicate the presence of racial disparity. In both high-risk and low-risk categories, African-Americans exhibit a higher recidivism rate, with approximately 6% difference compared to Caucasians. This suggests that the results favor Caucasians to a slight extent. However, it is important to note that these figures alone may not be sufficient evidence to conclude that COMPAS is unfair. Further analysis and examination are required to thoroughly assess the fairness of COMPAS, taking into account additional factors and conducting comprehensive investigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e4efd6e-0468-4009-9f43-fb63b90cfdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 873,  641],\n",
       "       [ 473, 1188]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "# \"high_score\" is COMPAS prediction and \"two_year_recid\" variable is actual recidivism\n",
    "dfAA = df[df.race == \"African-American\"]\n",
    "cmAA = confusion_matrix(dfAA['two_year_recid'], dfAA['high_score'])\n",
    "cmAA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d431af4-9177-415d-8151-09eb9dc8a3e9",
   "metadata": {},
   "source": [
    "Accuracy = (TP + TN) / T = (1188 + 873) / (873 + 641 + 473 + 1188) = 0.6491\n",
    "\n",
    "Precision = TP / (TP + FP) = 1188 / (1188 + 641) = 0.6495\n",
    "\n",
    "Recall = TP / (TP + FN) = 1188 / (1188 + 473) = 0.7152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d06c422e-db23-42f3-a099-d1d7e75fe399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[999, 282],\n",
       "       [408, 414]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCC = df[df.race == \"Caucasian\"]\n",
    "cmCC = confusion_matrix(dfCC['two_year_recid'], dfCC['high_score'])\n",
    "cmCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2e304-fc67-4877-a2d9-7cbac5324ac0",
   "metadata": {},
   "source": [
    "Accuracy = (TP + TN) / T = (414 + 999) / (414 + 999 + 282 + 408) = 0.6719\n",
    "\n",
    "Precision = TP / (TP + FP) = 414 / (414 + 282) = 0.5948\n",
    "\n",
    "Recall = TP / (TP + FN) = 414 / (414 + 408) = 0.5036"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b1286-94a7-4b62-9088-2469a9f457f0",
   "metadata": {},
   "source": [
    "a) The accuracy of COMPAS classification for African-Americans is 64.91%, and for Caucasians, it is 67.19%.\n",
    "\n",
    "b) FPR = FP / (TN + FP) = 641 / (873 + 641) = 0.4238. The FPR for African-Americans is 42.38%, indicating that 42.38% of African-American who were actually low risk according to COMPAS were wrongly classified as high risk.\n",
    "\n",
    "FPR = FP / (TN + FP) = 282 / (999 + 282) = 0.2205. The FPR for Caucasians is 22.05%, meaning that 22.05% of Caucasians who were actually low risk according to COMPAS were wrongly classified as high risk.\n",
    "\n",
    "c) FNR = FN / (TP + FN) = 473 / (1188 + 473) = 0.2848. The FNR for African-Americans is 28.48%, indicating that 28.48% of African-Americans who were actually high risk according to COMPAS were wrongly classified as low risk.\n",
    "\n",
    "FNR = FN / (TP + FN) = 408 / (414 + 408) = 0.4964. The false negative rate (FNR) for Caucasians is 49.64%, meaning that 49.64% of Caucasians who were actually high risk according to COMPAS were wrongly classified as low risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1cbea-6a22-4c3c-95ec-444a7b0896fd",
   "metadata": {},
   "source": [
    "Q4\n",
    "\n",
    "The accuracy of COMPAS in correctly categorizing individuals is quite similar for African-Americans and Caucasians, with only a 2.28% difference.\n",
    "\n",
    "However, the analysis in the previous question reveals disparities in the false positive rates favoring Caucasians. The false positive rate for Caucasians is 20% lower than that for African-Americans. This suggests that African-Americans with a low-risk classification have a 20% higher chance of being wrongly classified as high-risk compared to Caucasians.\n",
    "\n",
    "Additionally, the false negative rate favors Caucasians, as it is 22% higher than that for African-Americans. This implies that Caucasians with a high-risk classification have a 22% higher chance of being wrongly classified as low-risk compared to African-Americans.\n",
    "\n",
    "Based on this analysis, it becomes more evident that under similar circumstances, Caucasian offenders are more likely to escape harsh sentences compared to African-Americans. Conversely, African-Americans may face more unjust sentences compared to Caucasian offenders at the same risk level.\n",
    "\n",
    "These findings provide comparitively strong evidence that the COMPAS algorithm operates unfairly with regard to the offender's race, with a bias against African-Americans and in favor of Caucasian offenders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96678725-b8aa-498c-9041-05c4d33c446f",
   "metadata": {},
   "source": [
    "Q5\n",
    "\n",
    "My answer in question 4 aligns with my answer in question 2. In question 2, I discussed the racial disparity in recidivism rates, highlighting that African-Americans have higher rates compared to Caucasians in both the high-risk and low-risk categories. This suggests an imbalance that favors Caucasians to some extent.\n",
    "\n",
    "In question 4, I analyzed the accuracy, false positive rate, and false negative rate of the COMPAS algorithm for African-Americans and Caucasians. I pointed out the disparities in false positive and false negative rates, which favor Caucasians. These disparities align with the racial disparity observed in the recidivism rates mentioned in question 2.\n",
    "\n",
    "Therefore, my answer in question 4 further emphasizes the presence of racial bias in the COMPAS algorithm, supporting the notion that it operates unfairly by favoring Caucasians and potentially leading to unjust outcomes for African-Americans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804eb7e-2b49-48fc-a631-c0c1c882c0d0",
   "metadata": {},
   "source": [
    "## 2.1 Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392c7c8-bf84-4b29-883c-baf81e2058a5",
   "metadata": {},
   "source": [
    "Q1\n",
    "\n",
    "I think accuracy (A), false positive rate (FPR), and false negative rate (FNR) are appropriate performance measures for the model. \n",
    "\n",
    "Accuracy (A): Accuracy is a commonly used performance measure that provides an overall understanding of the model's correctness in predicting recidivism. It calculates the proportion of correctly classified instances (both true positives and true negatives) out of the total predictions. However, accuracy alone may not be sufficient when the classes are imbalanced or when the costs of false positives and false negatives differ significantly.\n",
    "\n",
    "False Positive Rate (FPR): FPR is the proportion of instances that are incorrectly classified as recidivists (positive class) among all the actual non-recidivists (negative class). FPR is particularly relevant in the context of fairness and avoiding biases. By assessing the FPR, we can measure how often the model wrongly identifies individuals as recidivists, which can help identify potential disparities in the treatment of different groups.\n",
    "\n",
    "False Negative Rate (FNR): FNR is the proportion of instances that are incorrectly classified as non-recidivists (negative class) among all the actual recidivists (positive class). FNR is also crucial to consider, as it captures the instances where the model fails to identify individuals who are likely to recidivate. High FNR may result in increased risks and negative consequences for individuals who should have been flagged as high risk but were not.\n",
    "\n",
    "By considering accuracy, FPR, and FNR together, we can gain a more comprehensive understanding of the model's performance, its ability to avoid biases, and its effectiveness in predicting recidivism accurately while minimizing both false positive and false negative errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58abf831-cfa8-4025-a885-e72e720ecea1",
   "metadata": {},
   "source": [
    "Q2\n",
    "\n",
    "We should not use variable decile score because it is known to be generated by the COMPAS model, which has faced criticism regarding its potential biases. To avoid explicit race and gender bias, it is important to consider features and variables that are not directly related to race or gender. By excluding the variable decile score and focusing on other relevant predictors that do not introduce bias, we can work towards creating a fair and unbiased model for predicting recidivism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "518e6053-2fd5-4834-adb5-b150d5d1126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.736064990512334\n",
      "FPR: 0.19105545617173525\n",
      "FNR: 0.3459524768425292\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "df_m = df.drop(columns=[\"decile_score\", \"race\", \"sex\", \"high_score\"])\n",
    "y = df_m.two_year_recid\n",
    "X = df_m.drop(\"two_year_recid\", axis=1)\n",
    "X = pd.get_dummies(X, columns = [\"c_charge_degree\", \"age_cat\"], drop_first=True)\n",
    "\n",
    "# create Logistic Regression model\n",
    "mLR = LogisticRegression()\n",
    "# Fit the model \n",
    "mLR.fit(X, y)\n",
    "# Perform 10-fold cross-validation\n",
    "cv = cross_val_score(mLR, X, y, cv=10, scoring = \"accuracy\")\n",
    "# Compute mean accuracy\n",
    "mean_accuracy = cv.mean()\n",
    "# Perform cross-validated predictions\n",
    "y_pred = cross_val_predict(mLR, X, y, cv=10)\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "# Calculate FPR\n",
    "FPR = cm[0, 1] / (cm[0, 0] + cm[0, 1])\n",
    "# Calculate FNR\n",
    "FNR = cm[1, 0] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "print(\"Accuracy:\", mean_accuracy)\n",
    "print(\"FPR:\", FPR)\n",
    "print(\"FNR:\", FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e43ba2da-ee5f-4c18-8cb8-0e323ca84d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6761985365993904\n",
      "FPR: 0.23685152057245082\n",
      "FNR: 0.4220700765203383\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_cv_scores = cross_val_score(dt_model, X, y, cv=10, scoring='accuracy')\n",
    "dt_mean_accuracy = dt_cv_scores.mean()\n",
    "\n",
    "dt_model.fit(X, y)\n",
    "dt_y_pred = cross_val_predict(dt_model, X, y, cv=10)\n",
    "dt_cm = confusion_matrix(y, dt_y_pred)\n",
    "dt_FPR = dt_cm[0, 1] / (dt_cm[0, 0] + dt_cm[0, 1])\n",
    "dt_FNR = dt_cm[1, 0] / (dt_cm[1, 0] + dt_cm[1, 1])\n",
    "\n",
    "print(\"Accuracy:\", dt_mean_accuracy)\n",
    "print(\"FPR:\", dt_FPR)\n",
    "print(\"FNR:\", dt_FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1adf631-74c1-4687-a45e-abeb67525205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6517562963601863\n",
      "FPR: 0.2819320214669052\n",
      "FNR: 0.42287555376560615\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_cv_scores = cross_val_score(knn_model, X, y, cv=10, scoring='accuracy')\n",
    "knn_mean_accuracy = knn_cv_scores.mean()\n",
    "\n",
    "knn_model.fit(X, y)\n",
    "knn_y_pred = cross_val_predict(knn_model, X, y, cv=10)\n",
    "knn_cm = confusion_matrix(y, knn_y_pred)\n",
    "knn_FPR = knn_cm[0, 1] / (knn_cm[0, 0] + knn_cm[0, 1])\n",
    "knn_FNR = knn_cm[1, 0] / (knn_cm[1, 0] + knn_cm[1, 1])\n",
    "\n",
    "print(\"Accuracy:\", knn_mean_accuracy)\n",
    "print(\"FPR:\", knn_FPR)\n",
    "print(\"FNR:\", knn_FNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb73ce-9ba1-4801-be92-a6a695d20c09",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| || | | | | |\n",
    "| -------- | ------------: | ------:|  ------:|  ------:| ------:| ------:|\n",
    "| | COMPAS | Logistic Regression | Decision Tree | KNN |\n",
    "|Accuracy| 0.658 | 0.7361 | 0.6762 | 0.6518 | \n",
    "|FPR| 0.33 | 0.1906 | 0.2369 | 0.2819 | \n",
    "|FNR| 0.355 | 0.3460 | 0.4221 | 0.4229 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deeffcd-6650-4741-87c5-95530ddd0074",
   "metadata": {},
   "source": [
    "In addition to the logistic regression model, I also implemented K-NN and Decision Trees models (use same variables as the logistic regression one). The results are presented in the above table. \n",
    "\n",
    "Based on these values, the Logistic Regression model has the highest accuracy, lowest FPR and relatively lower FNR compared to the other models. Since lower FPR values indicate better fairness in terms of falsely classifying low-risk individuals as high risk, and lower FNR values indicate better fairness in terms of falsely classifying high-risk individuals as low risk, in terms of fairness and accuracy, the Logistic Regression model appears to be the best choice among the four models. My best model Logistic Regression model got better result than COMPAS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2361293c-2fcd-4f68-9f00-2567ae2fe7b7",
   "metadata": {},
   "source": [
    "## 2.2 Is your model more fair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "119f11c8-52bd-491b-a72b-66e63306a4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3514115898959881,\n",
       " 0.6495352651722253,\n",
       " 0.2899786780383795,\n",
       " 0.5948275862068966)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "# COMPAS result for recidivism risk:\n",
    "lAA_recid, hAA_recid, lCC_recid, hCC_recid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8eddd2ce-968c-43c8-bb79-8dceebdb3e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race              predicted_r\n",
       "African-American  0              0.289409\n",
       "                  1              0.767892\n",
       "Caucasian         0              0.259853\n",
       "                  1              0.714521\n",
       "Name: two_year_recid, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My result (Logistic Regression):\n",
    "mLR = LogisticRegression()\n",
    "# Train the best model on all data\n",
    "mLR.fit(X, y)\n",
    "# Predict recidivism for all individuals\n",
    "all_predictions = mLR.predict(X)\n",
    "# Add the predicted recidivism to the original DataFrame\n",
    "df['predicted_r'] = all_predictions\n",
    "# Compute the percentage of the predicted low-risk and high-risk individuals who recidivate, by race\n",
    "df.groupby(['race', 'predicted_r'])['two_year_recid'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d59b1-0a9e-41f2-89d6-6cd868d6e833",
   "metadata": {},
   "source": [
    "| | | |\n",
    "| -------- | ------------: | ------:|\n",
    "| | COMPAS | DT |\n",
    "|low-risk African-American| 0.3514 | 0.2894 |\n",
    "|high-risk African-American | 0.6495 | 0.7678 |\n",
    "|low-risk Caucasian | 0.29 | 0.2598 |\n",
    "|high-risk Caucasian | 0.5948 | 0.7145 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6acbd-d574-48fb-b776-e8b24dc353e4",
   "metadata": {},
   "source": [
    "For African-Americans, my Logistic Regression model has a lower recidivism rate for low-risk individuals compared to COMPAS, indicating it is slightly more fair in this regard. However, for high-risk individuals, the Logistic Regression has a significantly higher recidivism rate, indicating it is less fair in this aspect.\n",
    "\n",
    "For Caucasians, my Logistic Regression model also has a lower recidivism rate for low-risk individuals compared to COMPAS, suggesting it is slightly more fair. However, similar to African-Americans, the recidivism rate for high-risk individuals is higher in the Logistic Regression model, indicating it is less fair in this aspect as well.\n",
    "\n",
    "Overall, based on the comparison of recidivism rates for low-risk and high-risk individuals by race, it appears that my Logistic Regression model is less fair than COMPAS. It results in higher recidivism rates for high-risk individuals, regardless of race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8a81ced-2c28-4b0b-be6e-6fb1cdf13e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African-American:\n",
      "FPR: 0.23778071334214002\n",
      "FNR: 0.28296207104154125\n",
      "Caucasian:\n",
      "FPR: 0.13505074160811867\n",
      "FNR: 0.4732360097323601\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# Filter the dataframe for African-Americans\n",
    "df_AA = df[df['race'] == 'African-American']\n",
    "cm_AA = confusion_matrix(df_AA['two_year_recid'], df_AA['predicted_r'])\n",
    "fpr_AA = cm_AA[0, 1] / (cm_AA[0, 0] + cm_AA[0, 1])\n",
    "fnr_AA = cm_AA[1, 0] / (cm_AA[1, 0] + cm_AA[1, 1])\n",
    "\n",
    "# Filter the dataframe for Caucasians\n",
    "df_CC = df[df['race'] == 'Caucasian']\n",
    "cm_CC = confusion_matrix(df_CC['two_year_recid'], df_CC['predicted_r'])\n",
    "fpr_CC = cm_CC[0, 1] / (cm_CC[0, 0] + cm_CC[0, 1])\n",
    "fnr_CC = cm_CC[1, 0] / (cm_CC[1, 0] + cm_CC[1, 1])\n",
    "\n",
    "# Print the FPR and FNR by race\n",
    "print(\"African-American:\")\n",
    "print(\"FPR:\", fpr_AA)\n",
    "print(\"FNR:\", fnr_AA)\n",
    "\n",
    "print(\"Caucasian:\")\n",
    "print(\"FPR:\", fpr_CC)\n",
    "print(\"FNR:\", fnr_CC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777070f8-e31d-4d6e-914d-5c1f2b83fcc3",
   "metadata": {},
   "source": [
    "| | | |\n",
    "| -------- | ------------: | ------:|\n",
    "| | COMPAS | DT |\n",
    "|FPR African-American| 0.4238 | 0.2378 |\n",
    "|FNR African-American | 0.2848 | 0.2830 |\n",
    "|FPR Caucasian | 0.2205 | 0.1351 |\n",
    "|FNR Caucasian | 0.4964 | 0.4732 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9708b52-611b-439d-b6c0-42e2c6a96522",
   "metadata": {},
   "source": [
    "For African-Americans, my Logistic Regression model has a significant lower FPR compared to COMPAS, indicating it is more fair in terms of falsely classifying low-risk individuals as high risk. The FNR is also slightly lower in the Logistic Regression model, indicating it is slightly more fair in terms of falsely classifying high-risk individuals as low risk.\n",
    "\n",
    "For Caucasians, my Logistic Regression model has a lower FPR compared to COMPAS, indicating it is more fair in terms of falsely classifying low-risk individuals as high risk. The FNR is also slightly lower in the Logistic Regression model, indicating it is slightly more fair in terms of falsely classifying high-risk individuals as low risk.\n",
    "\n",
    "Overall, considering both African-Americans and Caucasians, my Logistic Regression model appears to be more fair than COMPAS. It has significant lower FPR values and comparable lower FNR values for both racial groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fae1f8-3ce4-4f44-b829-b216e76d13db",
   "metadata": {},
   "source": [
    "Q3\n",
    "\n",
    "Based on the results from 2.2.1 and 2.2.2, there are some differences in the interpretation of fairness between the recidivism rates and the false positive/negative rates for my Logistic Regression model compared to COMPAS. \n",
    "\n",
    "In terms of recidivism rates, my Logistic Regression model shows lower rates for low-risk individuals but higher rates for high-risk individuals compared to COMPAS. This suggests a trade-off between fairness for different risk categories.\n",
    "\n",
    "However, when considering the false positive and false negative rates, my Decision Tree model generally performs better than COMPAS. It has lower FPR values for both African-Americans and Caucasians and comparable or slightly higher FNR values.\n",
    "\n",
    "While my  model may have certain advantages in terms of false positive/negative rates, the higher recidivism rates for high-risk individuals raise concerns about the fairness of the model in that aspect. Therefore, it would be necessary to carefully consider the specific fairness criteria, the trade-offs involved, and the context in which the model is being used to determine whether my model is better or worse than COMPAS in terms of overall fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247b2226-466a-498a-896f-385171c3ff01",
   "metadata": {},
   "source": [
    "I spend 14 hours on this ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e28fd0-ee74-42db-ae19-805c5e8ff8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
